{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b08b38f",
   "metadata": {},
   "source": [
    "# osiris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af12a35f",
   "metadata": {},
   "source": [
    "![img](https://dm2301files.storage.live.com/y4mmRC1xelS6Y6MEqUnZ-k2vjpADHpo6UMZAaZWROunr9-Ml5FYDlZ6WMxCGedy7NDhwDpusZdF5E1oLR5Qn6momydHe7tYUOMwNeFeGW7pUWkBjGPSnZp2sacYWs9IKkose6xjhSySL_v2tbfItRI7T_Pw_Tayhaa2F_vrwW6ucyr6WPa6s9DWH_if9Y5Y3yAU?width=375&height=250&cropmode=none)\n",
    "\n",
    "\n",
    "osiris is a Python data processing and analysis environment for data-based computational conflict forecasting using very large datasets and graph-based methods and models and visualization, powered by scalable graph databases.\n",
    "\n",
    "You can use osiris to analyze causal chains and networks of confict and violence around the world from realtime-updated, [automatically-encoded political event data](https://parusanalytics.com/eventdata/papers.dir/Schrodt_Yonamine_NewDirectionsInText.pdf) from projects like GDELT. This notebook gives an overview of the osiris project, the [GDELT project](https://www.gdeltproject.org/) data that osiris uses, how to import political event data using osiris either from the GDELT file server or from Google BigQuery, how to visualize and analyze it using Python, and how to load it into a TigerGraph graph server instance to efficiently run graph-centric queries on it to retrieve vertex-edge event data that can then be further analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26512f9",
   "metadata": {},
   "source": [
    "## Notebook Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b28c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# Check if running inside Colab or Kaggle\n",
    "IN_COLAB = 'COLAB_GPU' in os.environ\n",
    "IN_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "IN_HOSTED_NB = IN_COLAB or IN_KAGGLE\n",
    "os.environ['IN_HOSTED_NB'] = str(IN_HOSTED_NB)\n",
    "\n",
    "OS_NAME = sys.platform.upper()\n",
    "if OS_NAME in ['LINUX', 'DARWIN'] and IN_HOSTED_NB:\n",
    "  import subprocess\n",
    "  print('Installing osiris from GitHub...')\n",
    "  print(subprocess.run('if [ -d \"osiris\" ]; then rm -Rf osiris; fi', text=True, shell=True, check=True, capture_output=True).stdout)\n",
    "  print(subprocess.run('git clone https://github.com/allisterb/osiris --recurse-submodule', text=True, shell=True, check=True, capture_output=True).stdout)\n",
    "  print(subprocess.run('cd osiris && ./install', text=True, shell=True, check=True, capture_output=True).stdout)\n",
    "\n",
    "# If we're not in a hosted nb env assume we're running Jupyter from the osiris project directory root\n",
    "OSIRIS_PATH = '..' if not IN_HOSTED_NB else 'osiris'\n",
    "\n",
    "# Import the osiris code and set the runtime env. \n",
    "sys.path.append(os.path.join(OSIRIS_PATH, 'osiris'))\n",
    "sys.path.append(os.path.join(OSIRIS_PATH, 'ext'))\n",
    "from osiris_global import set_runtime_env\n",
    "set_runtime_env(interactive_nb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe908a",
   "metadata": {},
   "source": [
    "## GDELT Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e2df0",
   "metadata": {},
   "source": [
    "*From the  [GDELT project](https://www.gdeltproject.org/) website*:\n",
    ">The GDELT Project is a realtime network diagram and database of global human society for open research.\n",
    "![gf](https://www.gdeltproject.org/images/spinningglobe.gif)\n",
    "\n",
    ">The GDELT Project is an initiative to construct a catalog of human societal-scale behavior and beliefs across all countries of the world, connecting every person, organization, location, count, theme, news source, and event across the planet into a single massive network that captures what's happening around the world, what its context is and who's involved, and how the world is feeling about it, every single day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936099b",
   "metadata": {},
   "source": [
    "The GDELT [event data](http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf) contains hundreds of millions of automatically coded events extracted from news stories daily using NLU methods and models. Each event data row contains the following fields:\n",
    "1. *Actors*: Humans or organizations or states which initiate and are the target of event actions. Actors may have geographic information but not temporal. An event references exactly 2 actors: Actor1 and Actor2.\n",
    "2. *Actions*: Codes and other information which describe each event. Actions have both temporal and spatial attributes: an event time plus some geo information like latitude / longitude.  \n",
    "3. *SourceURL*: a URL that locates the *story* from which the event data was extracted.\n",
    "\n",
    "osiris can extract data directly from the GDELT file server. The advantage of this method is that you don't need to have any special credentials or server access (remember we're interested *open-source* indicators.). All the data is downloaded directly to your client machine or notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260316ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data directly from GDELT file server\n",
    "from data.gdelt import DataSource\n",
    "import pandas as pd\n",
    "gdelt = DataSource()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa777fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing GDELT events data for 7 day(s) from 04-14-2022 to 04-20-2022...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f643a65373467eadb821773cfad8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Import GDELT events data:   0%|          | 0/7 [00:00<?, ?day/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing GDELT events data for 7 day(s) from 04-14-2022 to 04-20-2022 completed in 90.37 s.\n"
     ]
    }
   ],
   "source": [
    "# Get event data for a 1 week period\n",
    "events = gdelt.import_data('events', 'Apr-14-2022', 'Apr-20-2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5501173",
   "metadata": {},
   "source": [
    "About a week's worth of event data in 2022 consists of about 700K events takes up about 340MB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0993b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32458701",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6533dfb",
   "metadata": {},
   "source": [
    "Event data is highly denormalized with many redundancies for ease of querying and coded using a hierachical coding system called [CAMEO](http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf) - Conflict and Mediation Event Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbfb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[['EventCode', 'CAMEOCodeDescription']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461005b9",
   "metadata": {},
   "source": [
    "We can query and filter event data directly using the Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all events that were geolocated in Ukraine\n",
    "uka_events = events[(events.ActionGeo_CountryCode == 'UP')]\n",
    "uka_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04772c",
   "metadata": {},
   "source": [
    "So about 50K of 700K events last week were coded as happening in Ukraine, not surprising given recent events. Many of those related to use of military force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMEO code 190 denotes 'use of military force'\n",
    "uka_events[uka_events.EventCode.str.startswith('190')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11cf5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Folium to plot these military force events on a map\n",
    "import folium\n",
    "folium.Map(\n",
    "    location=[48., 31.], \n",
    "    tiles=\"Stamen Toner\",\n",
    "    zoom_start=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4870745",
   "metadata": {},
   "outputs": [],
   "source": [
    "uka_map = folium.Map(\n",
    "    location=[48., 31.], \n",
    "    #tiles=\"Stamen Toner\",\n",
    "    zoom_start=6\n",
    ")\n",
    "uka_map\n",
    "uka_events_sample = uka_events[uka_events.EventCode.str.startswith('190')].sample(n=100)\n",
    "for r in uka_events_sample.itertuples():\n",
    "    m = folium.Marker(location=[r.ActionGeo_Lat, r.ActionGeo_Long],\n",
    "                      icon=folium.Icon(color=\"red\", icon=\"fire\", prefix=\"glyphicon\"),\n",
    "                      tooltip=str(r.Actor1CountryCode) + '->' + str(r.EventCode) + ' ' +  str(r.CAMEOCodeDescription) + '->' + str(r.Actor2CountryCode) +' on ' + str(r.SQLDATE)\n",
    "                     )\n",
    "    m.add_to(uka_map)\n",
    "uka_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.etl import shape_events_vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b030f",
   "metadata": {},
   "source": [
    "shape_events_vertices(uka_events_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc71bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas(desc=\"my bar!\")\n",
    "uka_events_sample.Actor1Code.fillna('', inplace = False)\n",
    "+ uka_events_sample.Actor1Name.fillna('', inplace = False)\n",
    "+ uka_events_sample.Actor1CountryCode.fillna('', inplace = False)\n",
    "#uka_events_sample.Actor1Code.fillna('', inplace = False)\n",
    "#+ uka_events_sample.Actor1Name.fillna('', inplace = False)\n",
    "#+ uka_events_sample.Actor1CountryCode.fillna('', inplace = False)\n",
    "#+ uka_events_sample.Actor1KnownGroupCode.fillna('', inplace = False)\n",
    "#dd.progress_apply(lambda r: \n",
    "                                # r.Actor1Code if not pd.isnull(r.CAMEOCodeDescription) else ''\n",
    "                                 #+ 'jjjj', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91350c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha1\n",
    "import binascii\n",
    "from osiris_global import tqdm_auto\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "def calc_actor1_id(r:pd.DataFrame):\n",
    "        tqdm.pandas(total=len(r), unit='row', desc='Hashing Actor1 ID')\n",
    "        return binascii.b2a_base64(sha1(''.join([\n",
    "            r.Actor1Code if not pd.isnull(r.Actor1Code) else '', \n",
    "            r.Actor1Name if not pd.isnull(r.Actor1Name) else '',\n",
    "            r.Actor1CountryCode if not pd.isnull(r.Actor1CountryCode) else '',\n",
    "            r.Actor1KnownGroupCode if not pd.isnull(r.Actor1KnownGroupCode) else '',\n",
    "            r.Actor1EthnicCode if not pd.isnull(r.Actor1EthnicCode) else '',\n",
    "            r.Actor1Religion1Code if not pd.isnull(r.Actor1Religion1Code) else '',\n",
    "            r.Actor1Religion2Code if not pd.isnull(r.Actor1Religion2Code) else '',\n",
    "            r.Actor1Type1Code if not pd.isnull(r.Actor1Type1Code) else '',\n",
    "            r.Actor1Type2Code if not pd.isnull(r.Actor1Type2Code) else '',\n",
    "            r.Actor1Type3Code if not pd.isnull(r.Actor1Type3Code) else '',\n",
    "            str(r.Actor1Geo_Type) if not pd.isnull(r.Actor1Geo_Type) else '',\n",
    "            r.Actor1Geo_FullName if not pd.isnull(r.Actor1Geo_FullName) else '',\n",
    "            r.Actor1Geo_CountryCode if not pd.isnull(r.Actor1Geo_CountryCode) else '',\n",
    "            r.Actor1Geo_ADM1Code if not pd.isnull(r.Actor1Geo_ADM1Code) else '',\n",
    "            r.Actor1Geo_ADM2Code if not pd.isnull(r.Actor1Geo_ADM2Code) else '',\n",
    "            str(r.Actor1Geo_Lat)if not pd.isnull(r.Actor1Geo_Lat) else '',\n",
    "            str(r.Actor1Geo_Long) if not pd.isnull(r.Actor1Geo_Long) else '',\n",
    "            str(r.Actor1Geo_FeatureID) if not pd.isnull(r.Actor1Geo_FeatureID) else '',     \n",
    "        ]).encode('utf-8')).digest()).strip().decode('utf-8')\n",
    "\n",
    "def calc_actor2_id(r:pd.DataFrame):\n",
    "        tqdm.pandas(total=len(r), unit='row', desc='Hashing Actor2 ID')\n",
    "        return binascii.b2a_base64(sha1(''.join([\n",
    "            r.Actor2Code if not pd.isnull(r.Actor2Code) else '', \n",
    "            r.Actor2Name if not pd.isnull(r.Actor2Name) else '',\n",
    "            r.Actor2CountryCode if not pd.isnull(r.Actor2CountryCode) else '',\n",
    "            r.Actor2KnownGroupCode if not pd.isnull(r.Actor2KnownGroupCode) else '',\n",
    "            r.Actor2EthnicCode if not pd.isnull(r.Actor2EthnicCode) else '',\n",
    "            r.Actor2Religion1Code if not pd.isnull(r.Actor2Religion1Code) else '',\n",
    "            r.Actor2Religion2Code if not pd.isnull(r.Actor2Religion2Code) else '',\n",
    "            r.Actor2Type1Code if not pd.isnull(r.Actor2Type1Code) else '',\n",
    "            r.Actor2Type2Code if not pd.isnull(r.Actor2Type2Code) else '',\n",
    "            r.Actor2Type3Code if not pd.isnull(r.Actor2Type3Code) else '',\n",
    "            str(r.Actor2Geo_Type) if not pd.isnull(r.Actor2Geo_Type) else '',\n",
    "            r.Actor2Geo_FullName if not pd.isnull(r.Actor2Geo_FullName) else '',\n",
    "            r.Actor2Geo_CountryCode if not pd.isnull(r.Actor2Geo_CountryCode) else '',\n",
    "            r.Actor2Geo_ADM1Code if not pd.isnull(r.Actor2Geo_ADM1Code) else '',\n",
    "            r.Actor2Geo_ADM2Code if not pd.isnull(r.Actor2Geo_ADM2Code) else '',\n",
    "            str(r.Actor2Geo_Lat)if not pd.isnull(r.Actor2Geo_Lat) else '',\n",
    "            str(r.Actor2Geo_Long) if not pd.isnull(r.Actor2Geo_Long) else '',\n",
    "            str(r.Actor2Geo_FeatureID) if not pd.isnull(r.Actor2Geo_FeatureID) else '',     \n",
    "        ]).encode('utf-8')).digest()).strip().decode('utf-8')\n",
    "\n",
    "def shape_events_vertices(events:pd.DataFrame):\n",
    "    events.insert(1, 'Actor1ID', events.progress_apply(calc_actor1_id, axis=1))\n",
    "    events.insert(2, 'Actor2ID', events.progress_apply(calc_actor2_id, axis=1))\n",
    "    return events\n",
    "\n",
    "shape_events_vertices(uka_events_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run below if running inside Colab and you want to pull env variables from a file called vars.env on your GDrive\n",
    "# !pip install colab-env --upgrade\n",
    "# import colab_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690b71f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
